{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835e269-5d1b-45b8-bb27-1a2d50285ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, Dataloader\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f0182-d6f6-423a-90ea-4167fb1a4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87463b28-7350-4c0b-afe7-c83bf238b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the tensorflow version\n",
    "def prepare(patient, root_dir, label_info):\n",
    "    path = Path(os.path.join(root_dir, bytes.decode(patient.numpy())))\n",
    "    images = [x for x in path if x.is_file()]\n",
    "    output = []\n",
    "    for image in images:\n",
    "        # convert to gray?\n",
    "        im = imread(image)\n",
    "        output.append(im)\n",
    "    label = label_info[patient]\n",
    "    if (len(output) > N):\n",
    "        print(\"Truncating input\")\n",
    "        output = output[:N]\n",
    "    return np.asarray(output), label\n",
    "\n",
    "def warp(filename, root_dir, label_info):\n",
    "    return tf.py_function(prepare, [filename, root_dir, label_info], [tf.float32, tf.float32])\n",
    "    \n",
    "def _load_dataset(filenames, root_dir, batch_size, label_dict):\n",
    "    files = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = files.map(lambda filename: warp(filename, root_dir, label_dict), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    fetchedDS = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    batchedDS = fetchedDS.batch(batch_size, drop_remainder=True)\n",
    "    return batchedDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df617b41-41da-4cb2-a237-5deceff23ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pytorch version\n",
    "class tileDataset(Dataset):\n",
    "    def __init__(self, tile_root_directory, patient_list, label_dict, data_transform):\n",
    "        super(tileDataset, self).__init__()\n",
    "        self.label_info = label_dict # a Path object\n",
    "        self.root_dir = tile_root_directory\n",
    "        self.patients = patient_list\n",
    "        self.transform = data_transform\n",
    "        \n",
    "    def __getitem(self, idx):\n",
    "        curr_patient = self.patients[idx]\n",
    "        # get tiles for this patient\n",
    "        lookup_dir = self.root_dir/curr_patient\n",
    "        tile_names = [x for x in lookup_dir if x.is_file()]\n",
    "        if len(tile_names > N):\n",
    "            print(f\"Input for patient {curr_patient} exceeds limit, truncating..\")\n",
    "            tile_names = tile_names[:N]\n",
    "        output = []\n",
    "        for t in tile_names:\n",
    "            img = imread(t)\n",
    "            img = self.transform(img).unsqueeze(0)\n",
    "            output.append(img)\n",
    "        output = torch.cat(output, dim=0)\n",
    "        label = self.label_dict[curr_patient]\n",
    "        return torch.tensor(output).float(), torch.tensor(label).long()\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d72304-b9c2-4e37-967c-879b14aaab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_performance_info(curr_loss, performance):\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, criterion, optimizer, performance_info):\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        update_performance_info(loss, performance_info)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Training batch loss {loss}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2d152-eb0a-454e-b290-6dd6f3808aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "patient_list = None\n",
    "label_dict = None\n",
    "batch = 2\n",
    "data_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "tiledata = tileDataset('../data/tiles/', patient_list, label_dict, data_transform)\n",
    "dloader = Dataloader(tiledata, batch_size=batch, shuffle=True)\n",
    "model = None # TODO\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e7621-ee38-4df2-9894-b6840937aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
