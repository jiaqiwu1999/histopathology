{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d835e269-5d1b-45b8-bb27-1a2d50285ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbbdad3-9873-49ea-8b7d-326c4251046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu found\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda:0'\n",
    "    print('gpu found')\n",
    "else:\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fdabc28-fb4c-45e4-b620-def468be380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a14f0182-d6f6-423a-90ea-4167fb1a4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61d72304-b9c2-4e37-967c-879b14aaab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_performance_info(curr_loss, performance):\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, criterion, optimizer, performance_info):\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        update_performance_info(loss, performance_info)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Training batch loss {loss}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e2d152-eb0a-454e-b290-6dd6f3808aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "gene = 'MKI67|4288'\n",
    "patient_info_file = '../data/patients_ids.txt'\n",
    "with open(patient_info_file, 'r') as f:\n",
    "    patient_list = f.read().splitlines()\n",
    "\n",
    "label_info_file = f'../data/labels/label_{gene}.csv'\n",
    "with open(label_info_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    label_dict = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "feature_files = list(glob.glob('../data/features/*.npy'))\n",
    "    \n",
    "feature_dataset = tileFeatureDataset(feature_files, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0bf81-9087-4ef4-ad95-8170297cfda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l = feature_dataset[0]\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "205e7621-ee38-4df2-9894-b6840937aa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input for patient TCGA-A8-A08X exceeds limit, truncating..\n",
      "Input for patient TCGA-BH-A0HQ exceeds limit, truncating..\n",
      "Input for patient TCGA-D8-A1JL exceeds limit, truncating..\n",
      "Input for patient TCGA-BH-A18M exceeds limit, truncating..\n",
      "Input for patient TCGA-D8-A27M exceeds limit, truncating..\n",
      "Input for patient TCGA-A2-A25D exceeds limit, truncating..\n",
      "Input for patient TCGA-C8-A27A exceeds limit, truncating..\n",
      "Input for patient TCGA-AC-A2FO exceeds limit, truncating..\n",
      "torch.Size([8, 3, 100, 224, 224])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 14.76 GiB total capacity; 13.52 GiB already allocated; 277.75 MiB free; 13.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3112/573666489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 14.76 GiB total capacity; 13.52 GiB already allocated; 277.75 MiB free; 13.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "batch = 8\n",
    "data_loader = DataLoader(feature_dataset, batch_size=batch, shuffle=True)\n",
    "# hyperparameters\n",
    "model = AttnClassifier.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "epoch = 10\n",
    "patients = 3\n",
    "\n",
    "for e in range(epoch):\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        print(X.shape)\n",
    "        output = model(X.to(device))\n",
    "        print(output.shape)\n",
    "        loss = criterion(output, y.to(device))\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # if i % 100 == 0:\n",
    "        #     print(f\"Training batch loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2d038-4558-4f6d-b04e-6b12c48d31c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
